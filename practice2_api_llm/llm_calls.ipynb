{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecfab3067516d52",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Usefull links:\n",
    "\n",
    "https://huggingface.co/docs/api-inference/detailed_parameters\n",
    "https://levelup.gitconnected.com/10-ways-to-run-open-source-models-with-llamaindex-84fd4b45d0cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b04989ccc748e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38796fc624fce1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:08:40.354901Z",
     "start_time": "2024-01-25T09:08:40.345295Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import OpenAI\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ.get('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1d228f57487a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example 1: LLChain /OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb25db6f9053755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:08:41.354753Z",
     "start_time": "2024-01-25T09:08:40.662414Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Answer: {'adjective': 'bad', 'text': '\\nWhy did the tomato turn red?\\n\\nBecause it saw the salad dressing!'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired!\n"
     ]
    }
   ],
   "source": [
    "## PROMPT\n",
    "prompt_template = \"Tell me a {adjective} joke\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\"], template=prompt_template\n",
    ")\n",
    "## LLM\n",
    "llm = LLMChain(llm=OpenAI(), prompt=prompt)\n",
    "print('---'*3)\n",
    "print('Answer:', llm.__call__(\"bad\"))\n",
    "print('Answer:', llm.run(\"good\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03c2ec32c129a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example 2: Witch request/ HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b29cb8cc886d475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:08:41.788543Z",
     "start_time": "2024-01-25T09:08:41.354499Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Can you please let us know more details about your iphone?\\n\\nIf you've got the iPhone 2S and would like to share an iOS device, please contact us.\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "headers = {\"Authorization\": f\"Bearer {HUGGINGFACEHUB_API_TOKEN}\"}\n",
    "\n",
    "\n",
    "query=\"Can you please let us know more details about your \"\n",
    "response = requests.post(API_URL, headers=headers, json=query).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd1eafb9f402b0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example 3: Witch request / HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f1cc4d9018b92f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T09:09:46.486418Z",
     "start_time": "2024-01-25T09:09:45.783058Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9326565265655518, 'start': 11, 'end': 16, 'answer': 'Clara'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
    "headers = {\"Authorization\": f\"Bearer {HUGGINGFACEHUB_API_TOKEN}\"}\n",
    "query={\n",
    "        \"inputs\": {\n",
    "            \"question\": \"What's my name?\",\n",
    "            \"context\": \"My name is Clara and I live in Berkeley.\",\n",
    "        }\n",
    "    }\n",
    "response = requests.post(API_URL, headers=headers, json=query).json()\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e81d4c8fe38375",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example 4: Summarize email/ HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31949c5dc325f9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:32:24.633679Z",
     "start_time": "2024-01-25T14:32:17.960266Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A customer\\'s coffee machine arrived ominously broken, evoking a profound sense of disbelief and despair. \"This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable,\" the customer writes. \"I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you,\" he adds.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_email = \"\"\"\n",
    "I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you. I am writing to pour my heart out about the recent unfortunate experience I had with one of your coffee machines that arrived ominously broken, evoking a profound sense of disbelief and despair.\n",
    "\n",
    "To set the scene, let me paint you a picture of the moment I anxiously unwrapped the box containing my highly anticipated coffee machine. The blatant excitement coursing through my veins could rival the vigorous flow of coffee through its finest espresso artistry. However, what I discovered within broke not only my spirit but also any semblance of confidence I had placed in your esteemed brand.\n",
    "\n",
    "Imagine, if you can, the utter shock and disbelief that took hold of me as I laid eyes on a disheveled and mangled coffee machine. Its once elegant exterior was marred by the scars of travel, resembling a war-torn soldier who had fought valiantly on the fields of some espresso battlefield. This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable\n",
    "\"\"\" \n",
    "summarizer = HuggingFaceHub(\n",
    "    repo_id=\"facebook/bart-large-cnn\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180}\n",
    ")\n",
    "def summarize(llm, text) -> str:\n",
    "    return llm(f\"Summarize this: {text}!\")\n",
    "\n",
    "summarize(summarizer, customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e359f506318126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:47:04.868837Z",
     "start_time": "2024-01-25T14:46:59.225203Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrorodriguezdeledesmajimenez/anaconda3/envs/general/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven this text, decide what is the issue the customer is concerned about. Valid categories are these:\n",
      "* product issues\n",
      "* delivery problems\n",
      "* missing or late orders\n",
      "* wrong product\n",
      "* cancellation request\n",
      "* refund or exchange\n",
      "* bad support experience\n",
      "* no clear reason to be upset\n",
      "\n",
      "Text: \n",
      "I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you. I am writing to pour my heart out about the recent unfortunate experience I had with one of your coffee machines that arrived ominously broken, evoking a profound sense of disbelief and despair.\n",
      "\n",
      "To set the scene, let me paint you a picture of the moment I anxiously unwrapped the box containing my highly anticipated coffee machine. The blatant excitement coursing through my veins could rival the vigorous flow of coffee through its finest espresso artistry. However, what I discovered within broke not only my spirit but also any semblance of confidence I had placed in your esteemed brand.\n",
      "\n",
      "Imagine, if you can, the utter shock and disbelief that took hold of me as I laid eyes on a disheveled and mangled coffee machine. Its once elegant exterior was marred by the scars of travel, resembling a war-torn soldier who had fought valiantly on the fields of some espresso battlefield. This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable\n",
      "\n",
      "Category:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "The email was sent by a customer whose coffee machine was broken. The customer was left distraught and inconsolable. The email was written in the form of a letter to the owner of the coffee machine. For confidential support call the Samaritans on 08457 90 90 90, visit a local Samaritans branch or see www.samaritans.org.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Given this text, decide what is the issue the customer is concerned about. Valid categories are these:\n",
    "* product issues\n",
    "* delivery problems\n",
    "* missing or late orders\n",
    "* wrong product\n",
    "* cancellation request\n",
    "* refund or exchange\n",
    "* bad support experience\n",
    "* no clear reason to be upset\n",
    "\n",
    "Text: {email}\n",
    "Category:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"email\"])\n",
    "# llm = VertexAI()\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"facebook/bart-large-cnn\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180}\n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "print(llm_chain.run(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2eefd8-a2a0-445a-a7a5-499e4c496c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee6119-40da-4a9e-8c9c-8e13308393db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dc096-72b7-4b94-8896-e630b0035aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
